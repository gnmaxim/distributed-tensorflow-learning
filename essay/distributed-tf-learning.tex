\documentclass[DIV=calc, paper=a4, fontsize=11pt]{scrartcl}	 % A4 paper and 11pt font size
%\documentclass[DIV=calc, paper=a4, fontsize=11pt, twocolumn]{scrartcl}	 % A4 paper and 11pt font size

\usepackage{multicol}
\usepackage{lipsum}
\usepackage[italian]{babel}
\usepackage[protrusion=true,expansion=true]{microtype}
\usepackage{amsmath,amsfonts,amsthm}
\usepackage[svgnames]{xcolor}
\usepackage[hang, small,labelfont=bf,up,textfont=it,up]{caption}
\usepackage{booktabs}
\usepackage{fix-cm}
\usepackage[margin=1in]{geometry}
\usepackage[utf8]{inputenc}
\setlength{\columnsep}{.6cm}

\usepackage{sectsty}
\allsectionsfont{\usefont{OT1}{phv}{b}{n5}}
\usepackage{fancyhdr}
\pagestyle{fancy}
\usepackage{lastpage}

% Headers - all currently empty
\lhead{}
\chead{}
\rhead{}

% Footers
\lfoot{}
\cfoot{}
\rfoot{\footnotesize Page \thepage\ of \pageref{LastPage}} % "Page 1 of 2"

\renewcommand{\headrulewidth}{.0pt} % No header rule
\renewcommand{\footrulewidth}{.4pt} % Thin footer rule

\usepackage{lettrine} % Package to accentuate the first letter of the text
\newcommand{\initial}[1]{ % Defines the command and style for the first letter
\lettrine[lines=3,lhang=0.3,nindent=0em]{
\color{DarkGoldenrod}
{\textsf{#1}}}{}}

\usepackage{titling} % Allows custom title configuration

\newcommand{\HorRule}{\color{DarkGoldenrod} \rule{\linewidth}{1pt}} % Defines the gold horizontal rule around the title

\pretitle{\vspace{-30pt} \begin{flushleft} \HorRule \fontsize{30}{30} \usefont{OT1}{phv}{b}{n} \color{DarkRed} \selectfont} % Horizontal rule before the title

\title{TensorFlow e Prove di Apprendimento Distribuito} % Your article title

\posttitle{\par\end{flushleft}\vskip 2em} % Whitespace under the title

\preauthor{\begin{flushleft}\large \lineskip 0.4em \usefont{OT1}{phv}{b}{sl} \color{DarkRed}} % Author font configuration

\author{Maxim Gaina e Bartolomeo Lombardi} % Your name

\postauthor{\footnotesize \usefont{OT1}{phv}{m}{sl} \color{Black} % Configuration for the institution name
\\ Lavoro di progetto per Sistemi Peer-to-Peer, Università degli Studi di Bologna % Your institution

\par\end{flushleft}\HorRule} % Horizontal rule after the title

\date{} % Add a date here if you would like one to appear underneath the title block


\begin{document}
	\maketitle
	\thispagestyle{fancy}
	% The first character should be within \initial{}
	\initial{Q}\textbf{uesto lavoro mira ad apprendere e riassumere le basi di TensorFlow \cite{tf}, il quale, come da definizione, è un'interfaccia per esprimere algoritmi nell'ambito di Machine Learning con anche la possibilità di implementarli. Successivamente l'intenzione sarà quella di esplorare le primitive offerte in ambito del calcolo distribuito e, dato un problema facilmente risolvibile tramite reti neurali, fare delle prove pratiche per ottenere una soluzione soddisfacente usando un sistema di macchine connesse.}
	
	\begin{multicols}{2}
		\tableofcontents
		\section*{Cosa è TensorFlow}
			TensorFlow nasce dalla necessità di avere un sistema con le giuste proprietà e requisiti per \textit{allenare} e usare reti neurali in ambienti distribuiti su larga scala e non. La computazione di un programma scritto in TensorFlow è eseguibile su piattaforme multiple ed eterogenee con poco o senza alcun cambiamento. Per ogni piattaforma presa in considerazione, è previsto lo sfruttamento dei diversi device a sua disposizione con capacità di calcolo, come processori centrali e acceleratori di grafica. Le computazioni vengono espresse da flussi di dati che scorrono all'interno di un grafo, e con i nodi che lo compongono che hanno un loro stato. Ulteriori obiettivi sono quelli di fornire un linguaggio \textit{flessibile}, che permetta la rapida implementazione di diversi modelli; un linguaggio il più possibile \textit{performante} nonostante la flessibilità appena citata; e forme di parallelismo con requisiti più o meno forti, anche per passare con facilità da ambienti isolati ad ambienti distribuiti.
			
		\section{Paradigma e Concetti Base}
			Una computazione TensorFlow è descritta da un \textit{grafo diretto} composto da un insieme di \textit{nodi}. Il grafo supporta computazioni che sono flussi di dati attraverso sé. I nodi mantengono e aggiornano i propri stati persistenti tramite estensioni, che permettono di creare anche cicli e altre strutture. Ogni nodo ha zero o più input e output ed è l'istanziazione di un'operazione. I valori che \textit{fluiscono } nel grafo sono detti \textbf{tensor}, array di dimensione $n$ nel quale ogni elemento ha tipo determinato a tempo di costruzione del grafo. Esistono anche particolari tipi di archi il cui unico scopo è quello di indicare le dipendenze fra nodi, cioè l'ordine di esecuzione. Vediamo ora meglio alcuni concetti.
			
			\begin{description}
				\item[Operazione] Avente nome e attributi, rappresenta l'astrazione di una computazione (p.e. \texttt{add}, \texttt{mulmatrix}) su tensors in ingresso.
				\item[Kernel] Implementazione particolare di un'operazione che le permette di essere eseguito su device particolari come una \texttt{GPU CUDA}.
				\item[Sessione] I grafi dell'utente interagiscono con TensorFlow (vengono lanciati) tramite sessioni, le quali, avendo un'interfaccia, possono essere usate anche per modificare il grafo a runtime. Le sessioni hanno quindi un'operazione \textit{Run} che prendono in input il grafo stesso e i tensori da dargli in pasto.
				\item[Variabili] I grafi vengono spesso eseguiti più volte e i tensors devono sopravvivere fra un'esecuzione e l'altra, per questo sono state create le variabili che salvano il loro valore, quando necessario. Le variabili sono anche esse tipi di nodo.
			\end{description}
		
		\section{Implementazione}
		
		\section{Estensioni}
		
		\section{Appunti Bart}
		
		\begin{thebibliography}{9}
			\bibitem{tf}
			Google Research,
			\emph{TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems},
			Preliminary White Paper,
			2015.
		\end{thebibliography}
	\end{multicols}

\end{document}